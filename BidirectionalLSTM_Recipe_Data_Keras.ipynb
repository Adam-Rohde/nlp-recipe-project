{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BidirectionalLSTM_Recipe_Data_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f2_9zuVlxcL",
        "colab_type": "code",
        "outputId": "cb7b0cc2-fafd-4a43-afef-14947e84525e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "Bi Directional LSTM Autoencoder\n",
        "'''\n",
        "\n",
        "from numpy import array\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM,GRU,Bidirectional\n",
        "from keras.layers import Dense\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.preprocessing import sequence\n",
        "import sklearn.metrics\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRYDEsEC2moD",
        "colab_type": "code",
        "outputId": "c0469043-eeca-4f19-8f5e-e99342676730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ESJCTJ2tym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################\n",
        "################################\n",
        "################################\n",
        "#Load Data\n",
        "\n",
        "#Lang class: create unique word index dictionary\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "#import data\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/CS 263 Project/baking_data_title_ingredients.pickle','rb') as f:\n",
        "    baking_data = pickle.load(f)\n",
        "\n",
        "joined_limited = baking_data[0]\n",
        "cleaned_recipes = baking_data[1]\n",
        "numerical_tokens_train = baking_data[2]\n",
        "numerical_tokens_test = baking_data[3]\n",
        "numerical_tokens_test_masked = baking_data[4]\n",
        "IDs_train = baking_data[5]\n",
        "IDs_test = baking_data[6]\n",
        "#vocabulary_dict = baking_data[7]\n",
        "#vocabulary = baking_data[8]\n",
        "cleaned_recipes_IDs = baking_data[9]\n",
        "\n",
        "MAX_LENGTH = max([len(s) for s in numerical_tokens_train])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOOvVXibpemP",
        "colab_type": "code",
        "outputId": "b3052471-2c47-41a1-dcd2-aaa001f390fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#cut data down to recipes len 100\n",
        "#data = numerical_tokens_train\n",
        "MAX_LENGTH = 75\n",
        "#prep data -- subset, make into list, normalize and create vocab\n",
        "def prep(dta):\n",
        "    temp = dta\n",
        "    temp = [temp[i] for i in range(0,len(temp)) if len(temp[i].split())<= MAX_LENGTH]\n",
        "    v = Lang('vocab')\n",
        "    for d in temp:\n",
        "        v.addSentence(d)\n",
        "    print(\"Counted words: \",v.n_words)\n",
        "    return temp,v\n",
        "\n",
        "data_strings, vocabulary = prep(cleaned_recipes)\n",
        "titles = [joined_limited.loc[i,\"title\"] for i in range(0,len(cleaned_recipes)) if len(cleaned_recipes[i].split())<= MAX_LENGTH]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counted words:  25095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "813D-wEqBp21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [[vocabulary.word2index[w] for w in s.split(\" \")] for s in data_strings]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWDQBdL9zPQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pad \n",
        "data = sequence.pad_sequences(data, maxlen=MAX_LENGTH,dtype='int32',value=0.0,padding=\"post\")\n",
        "\n",
        "# reshape input into [samples, timesteps, features]\n",
        "n_examples = len(data)\n",
        "n_words = MAX_LENGTH\n",
        "data = data.reshape((n_examples, n_words, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMaHI1egxAVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################\n",
        "################################\n",
        "################################\n",
        "#Model\n",
        "\n",
        "#define EncoderDecoder Layers\n",
        "hidden_size = 512\n",
        "EncoderDecoder = Sequential()\n",
        "EncoderDecoder.add(Bidirectional(LSTM(hidden_size, activation='sigmoid', input_shape=(n_words,1))))\n",
        "EncoderDecoder.add(RepeatVector(n_words))\n",
        "EncoderDecoder.add(Bidirectional(LSTM(hidden_size, activation='sigmoid', return_sequences=True)))\n",
        "EncoderDecoder.add(TimeDistributed(Dense(vocabulary.n_words ,activation=\"softmax\")))\n",
        "\n",
        "#define optimizer and loss\n",
        "optim = keras.optimizers.RMSprop(learning_rate=0.001)#,decay=0.99)\n",
        "EncoderDecoder.compile(optimizer=optim,loss=\"sparse_categorical_crossentropy\",metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5_5aMYCzUaV",
        "colab_type": "code",
        "outputId": "8adbead9-b192-40cf-81c8-32b0d8485707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#fit EncoderDecoder\n",
        "history = EncoderDecoder.fit(x=data, y=data, epochs=10, verbose=1,batch_size=100,shuffle=True,validation_split = 0.05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 122906 samples, validate on 6469 samples\n",
            "Epoch 1/10\n",
            "122906/122906 [==============================] - 1047s 9ms/step - loss: 0.9661 - sparse_categorical_accuracy: 0.7923 - val_loss: 1.0733 - val_sparse_categorical_accuracy: 0.7812\n",
            "Epoch 2/10\n",
            "122906/122906 [==============================] - 1039s 8ms/step - loss: 1.0016 - sparse_categorical_accuracy: 0.7892 - val_loss: 1.0538 - val_sparse_categorical_accuracy: 0.7845\n",
            "Epoch 3/10\n",
            "122906/122906 [==============================] - 1034s 8ms/step - loss: 0.9560 - sparse_categorical_accuracy: 0.7939 - val_loss: 1.0391 - val_sparse_categorical_accuracy: 0.7862\n",
            "Epoch 4/10\n",
            "122906/122906 [==============================] - 1045s 9ms/step - loss: 0.9764 - sparse_categorical_accuracy: 0.7922 - val_loss: 1.2598 - val_sparse_categorical_accuracy: 0.7529\n",
            "Epoch 5/10\n",
            "122906/122906 [==============================] - 1038s 8ms/step - loss: 1.0619 - sparse_categorical_accuracy: 0.7867 - val_loss: 1.1646 - val_sparse_categorical_accuracy: 0.7622\n",
            "Epoch 6/10\n",
            "122906/122906 [==============================] - 1040s 8ms/step - loss: 0.9524 - sparse_categorical_accuracy: 0.7948 - val_loss: 1.1163 - val_sparse_categorical_accuracy: 0.7824\n",
            "Epoch 7/10\n",
            "122906/122906 [==============================] - 1043s 8ms/step - loss: 0.9448 - sparse_categorical_accuracy: 0.7964 - val_loss: 1.1188 - val_sparse_categorical_accuracy: 0.7706\n",
            "Epoch 8/10\n",
            "122906/122906 [==============================] - 1035s 8ms/step - loss: 0.9886 - sparse_categorical_accuracy: 0.7928 - val_loss: 1.2363 - val_sparse_categorical_accuracy: 0.7620\n",
            "Epoch 9/10\n",
            "122906/122906 [==============================] - 1042s 8ms/step - loss: 0.9995 - sparse_categorical_accuracy: 0.7925 - val_loss: 1.3219 - val_sparse_categorical_accuracy: 0.7488\n",
            "Epoch 10/10\n",
            "122906/122906 [==============================] - 1047s 9ms/step - loss: 1.0233 - sparse_categorical_accuracy: 0.7916 - val_loss: 1.3073 - val_sparse_categorical_accuracy: 0.7469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7njsYcD3f7uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LODAj2aZ7Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model and architecture to single file\n",
        "EncoderDecoder.save(\"/content/drive/My Drive/CS 263 Project/BiLSTM_EncoderDecoder.h5\")\n",
        "Encoder.save(\"/content/drive/My Drive/CS 263 Project/BiLSTM_Encoder.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqf-8UH3aRMH",
        "colab_type": "code",
        "outputId": "df0d2962-ba59-4f29-af16-c58b4a3530ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "#load model \n",
        "from keras.models import load_model\n",
        "EncoderDecoder = load_model('/content/drive/My Drive/CS 263 Project/BiLSTM_EncoderDecoder.h5')\n",
        "EncoderDecoder.summary()\n",
        "\n",
        "Encoder = load_model('/content/drive/My Drive/CS 263 Project/BiLSTM_Encoder.h5')\n",
        "Encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 1024)              2105344   \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 75, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 75, 1024)          6295552   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 75, 25095)         25722375  \n",
            "=================================================================\n",
            "Total params: 34,123,271\n",
            "Trainable params: 34,123,271\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1_input (InputLay (None, 75, 1)             0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1024)              2105344   \n",
            "=================================================================\n",
            "Total params: 2,105,344\n",
            "Trainable params: 2,105,344\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8qd6tt7yfF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get embeddings\n",
        "# make encoder LSTM output layer \n",
        "Encoder = Model(inputs=EncoderDecoder.inputs, outputs=EncoderDecoder.layers[0].output)\n",
        "# get the feature vector for the input sequence\n",
        "embeddings = Encoder.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTq4w5hyzAqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get embeddings for recipies with nutritional info\n",
        "with open('/content/drive/My Drive/CS 263 Project/nutritional_info.pickle','rb') as f:\n",
        "    nutritional_info = pickle.load(f)\n",
        "\n",
        "embeddings_IDs = [cleaned_recipes_IDs[i] for i in range(0,len(cleaned_recipes_IDs)) if len(cleaned_recipes[i].split())<= MAX_LENGTH]\n",
        "nutri_embeddings_indices = [i for i, val in enumerate(embeddings_IDs) if val in nutritional_info[\"id\"].tolist()]\n",
        "\n",
        "nutri_embeddings_IDs = [embeddings_IDs[i] for i in nutri_embeddings_indices]\n",
        "nutri_embeddings = [embeddings[i] for i in nutri_embeddings_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuuA-8rq0Z3I",
        "colab_type": "code",
        "outputId": "47bd80f9-cb2d-491e-e619-282fd24b9905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#create matrix of cosine similarities for recipes with nutritional info and save with IDs\n",
        "cosine_similarities = sklearn.metrics.pairwise.cosine_similarity(nutri_embeddings, Y=None, dense_output=False)\n",
        "print(cosine_similarities)\n",
        "\n",
        "import pickle\n",
        "similarity_pickle = [nutri_embeddings,nutri_embeddings_IDs,cosine_similarities]\n",
        "with open('/content/drive/My Drive/CS 263 Project/BiLSTM_similarity.pickle', 'wb') as f:\n",
        "    pickle.dump(similarity_pickle, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.73904777 0.9318962  ... 0.8161352  0.84764385 0.8447449 ]\n",
            " [0.73904777 0.9999996  0.73619807 ... 0.73694193 0.6662061  0.6641311 ]\n",
            " [0.9318962  0.73619807 0.99999994 ... 0.83504045 0.87973225 0.8842382 ]\n",
            " ...\n",
            " [0.8161352  0.73694193 0.83504045 ... 1.         0.7800162  0.81985694]\n",
            " [0.84764385 0.6662061  0.87973225 ... 0.7800162  1.0000001  0.94240695]\n",
            " [0.8447449  0.6641311  0.8842382  ... 0.81985694 0.94240695 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}